# Volume II: Emergence of Spacetime

**(第二卷：时空的涌现机制)**

## Chapter 3: Limits of Causal Connectivity

**(第三章：因果连通性的极限)**

### 3.2 The Information-Theoretic Origin of Special Relativity

**(狭义相对论的信息论起源)**

> **"Relativity is not a theory about 'motion,' but a protocol about 'information synchronization.' When a distributed computing system must maintain data consistency under finite bandwidth constraints, Lorentz transformations are the only mathematically legitimate coordinate transformation scheme. Time dilation is not magic; it is resource throttling enforced by the system to prevent data overflow."**

In section 3.1, we established the physical essence of the speed of light $c$ as system bus bandwidth. In classical physics, special relativity is usually built on Einstein's two postulates: the principle of relativity and the constancy of the speed of light. However, in the axiomatic framework of Interactive Computational Cosmology (ICC), we cannot accept "postulates"; we must derive these phenomena from underlying computational mechanisms.

This section will prove that once we accept the two premises of "finite computational resources" and "causal locality," the effects of special relativity—time dilation, length contraction, and the relativity of simultaneity—are inevitable algorithmic results for maintaining logical self-consistency in network systems.

#### 3.2.1 Reference Frames as Serialization Protocols

In distributed systems theory, there is no such thing as a "global clock." The system consists of countless concurrently running processes (particles/observers) that coordinate states by exchanging messages (photons).

**Definition 3.2.1 (Physical Reference Frame)**

In computational ontology, a **Reference Frame** is essentially a **Serialization Protocol**. It attempts to map the partial order set of discrete events occurring in the universe (defined by causal relationships $\preceq$) onto an observer's linear time axis $t$.

* **Rest Frame**: The observer's own master frequency clock.

* **Moving Frame**: The observer attempts to parse the state sequence of another asynchronously running process.

Due to hard bandwidth delay ($c$) in information propagation, when an observer attempts to synchronize states with an object moving rapidly (frequently updating position data), specific algorithms must be used to compensate for transmission delay. If this algorithm requires maintaining causality without violation (i.e., no `IndexError` of effect before cause), then **Lorentz Transformation** is the only linear transformation group satisfying the conditions.

#### 3.2.2 Resource Contention and Time Dilation: $v_{ext}^2 + v_{int}^2 = c^2$

The most famous prediction of special relativity is time dilation: moving clocks run slow. In standard interpretation, this is a rotation of spacetime geometry. But in computational cosmology, this is a direct consequence of **Resource Contention**.

According to the Axiom of Finite Information established in Volume I, every physical entity (object) has an upper limit on the total amount of information it can process per unit time, which is the Planck frequency, corresponding to the macroscopic speed of light $c$. This "computational budget" must be allocated to two types of tasks:

1.  **External Displacement (External Processing, $v_{ext}$)**: Processing coordinate updates of the object in grid space. This is an I/O-intensive task.

2.  **Internal Evolution (Internal Processing, $v_{int}$)**: Processing updates of the object's internal states (such as atomic oscillations, cellular metabolism, thought processes). This is a CPU-intensive task.

**Theorem 3.2.1 (Computational Power Conservation Theorem / Optical Path Conservation)**

For any isolated physical entity, its displacement velocity $v_{ext}$ in external space and its internal time flow velocity $v_{int}$ follow the Pythagorean conservation law:

$$
v_{ext}^2 + v_{int}^2 = c^2
$$

**Proof and Derivation**:

In Hilbert space, the unitary evolution operator $\hat{U}$ rotates the state vector at a constant rate. This rate is $c$ (in natural units).

When we observe a stationary object, all its computational power is used for internal evolution, so $v_{ext}=0, v_{int}=c$. At this point, its internal clock runs fastest (proper time $\tau = t$).

When we observe a moving object, it must allocate part of its computational power to handle the "position change" operation. Since the total bandwidth $c$ is locked, its available internal computational power $v_{int}$ must decrease:

$$
v_{int} = \sqrt{c^2 - v_{ext}^2} = c \sqrt{1 - \frac{v_{ext}^2}{c^2}}
$$

This is exactly the reciprocal of the relativistic factor $\gamma = 1/\sqrt{1 - v^2/c^2}$.

**Physical Interpretation**:

The reason you see moving people age slowly is not because "time" itself performs magic, but because their system is busy handling the high-priority thread of "movement," causing CPU cycles for the background thread of "aging" to be forcibly reduced. This is a **system-level lag**.

#### 3.2.3 Length Contraction as Sampling Aliasing

Length contraction is often misunderstood as physical compression of objects. From an information-theoretic perspective, this is actually a **Sampling Artifact** or **bandwidth compression**.

When we measure the length of a moving object, we are essentially asking: obtain the coordinates $x_1$ of the object's head and $x_2$ of its tail "simultaneously."

But in distributed networks, due to the speed of light limit, "simultaneity" is relative.

**Definition 3.2.2 (Measurement as Slicing)**

Measuring length is performing a spatial slice on a four-dimensional world tube.

For an object moving at velocity $v$, its data packets carry enormous Doppler shift when transmitted on the grid. To receive complete data frames within a limited bandwidth window, the receiver (observer) must perform **Downsampling** on the data.

* **Blue Shift of Spatial Frequency**: The object moves relative to the observer, causing an increase in the number of grid cells scanned per unit time (increased spatial frequency).

* **Nyquist Sampling Theorem**: To avoid information loss, under bandwidth constraints, the spatial sampling interval must be compressed.

Mathematically, this necessary spatial coordinate rescaling to maintain causal consistency manifests as:

$$L' = L \sqrt{1 - \frac{v^2}{c^2}}$$

This is like in video streaming: if network bandwidth is insufficient (limited by $c$), to maintain smooth playback (temporal continuity), the system automatically reduces image resolution (spatial contraction).

#### 3.2.4 Lorentz Group: Automorphism Group of Causal Networks

Now we can give the ultimate definition of special relativity. It is not geometry about spacetime, but algebra about **computational network topology**.

In the interactive computational universe, all physical laws must remain invariant under **Lorentz transformations**. What does this mean in computer science?

**Theorem 3.2.2 (Protocol Independence)**

The Lorentz covariance of physical laws is equivalent to **Eventual Consistency** in distributed systems. This means: regardless of which serialization protocol we adopt (i.e., regardless of which reference frame we are in) to process event streams, the topological structure of the system's **Logical Causal Graph** remains unchanged.

* **Lorentz Group $SO(3,1)$**: The set of all coordinate transformation operations that preserve the **system bus bandwidth limit ($ds^2 = 0$)**.

* **Invariant $ds^2$**: Geometrically it is spacetime distance; computationally it is **Causal Distance**. It measures the minimum number of logical clock cycles required for information exchange between two events.

**Summary**:

Special relativity is the **I/O scheduling algorithm** of the universe operating system. By dynamically adjusting each process's **local clock frequency (time dilation)** and **memory addressing stride (length contraction)**, it ensures that under hardware conditions with limited bus bandwidth ($c$), no data packet can violate the read-after-write constraint of causal logic.
